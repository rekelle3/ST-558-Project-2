---
output: rmarkdown::github_document
params: 
  dayofWeek: NULL
---

# Introduction

The data we will be analyzing in this project is a daily count of rental bikes between years 2011 and 2012 in the Capital bikeshare system. This bike share data set includes information about the day of rental and the weather on that particular day. Below is a list of the variables that will be available for us to include in our models and a brief description:

* `season` : season (1:winter, 2:spring, 3:summer, 4:fall)
* `yr` : year (0: 2011, 1:2012)
* `mnth` : month ( 1 to 12)
* `holiday` : weather day is holiday or not
* `weekday` : day of the week
* `workingday` : if day is neither weekend nor holiday is 1, otherwise is 0
* `weathersit` :
  + 1: Clear, Few clouds, Partly cloudy, Partly cloudy
  + 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist
  + 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds
  + 4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog
* `temp` : Normalized temperature in Celsius
* `atemp`: Normalized feeling temperature in Celsius
* `hum`: Normalized humidity
* `windspeed`: Normalized wind speed
* `cnt`: count of total rental bikes

The purpose of this analysis is to compare two models in terms of their predictive performance. As this is a regression problem, we will use RMSE to determine which model is the better fit. The models we will fit are a non-ensemble tree model and a boosted tree model. Tuning parameters for both models will be selected using leave one out cross validation. We will fit both of these models on the training data set and evaluate the RMSE on the test set. 

# Loading Packages

We will load in our necessary packages, `tidyverse` and `caret`. We will also set the seed, so our results are reproducible. 

```{r}
set.seed(123)
library(tidyverse)
library(caret)
library(ggplot2)
```

# Reading in Data

Using the `read_csv` function, we will read in the csv file of the bike sharing data. With the use of the `select` function, we can remove the `casual` and `registered` variables, which should not be used for modeling, and any non-numeric variables, like `dteday`. Finally, using `filter`, we will filter our data set by the specific day of the week we are interested in analyzing for that report. 

```{r, message = FALSE}
bikeData <- read_csv("day.csv")
bikeData <- bikeData %>% select(-c(casual, registered, instant, dteday)) %>% filter(weekday == params$dayofWeek)
```

# Creating Training and Test Split

Using `createDataPartition`, we will partition our data into the 70/30 training and test split. 

```{r}
bikeDataIndex <- createDataPartition(bikeData$cnt, p = 0.7, list = FALSE)
bikeDataTrain <- bikeData[bikeDataIndex, ]
bikeDataTest <- bikeData[-bikeDataIndex, ]
```

# Summarizations of Data

First, we will take a look at the five number summary of each variable available in the data set. 

```{r}
summary(bikeDataTrain)
```

From this output, we can see that the `yr`, `holiday`, and `workingday` variables are binary, that is they take on values of 0 or 1. Also, the `season`, `mnth`, and `weathersit` variables are categorical. We will create contingency tables of these non-numeric variables and the count of bikes shared. To create these tables, we will use the `aggregate` function in combination with `kable`. First, we will create the table of `year` and `cnt`.

```{r}
knitr::kable(aggregate(bikeDataTrain$cnt, by = list(bikeDataTrain$yr), FUN = sum), col.names = c("Year", "Sum of Count"))
```

From the table, we can see that the bike share rented out more bikes in the year 2012, suggesting that the bike sharing company had better performance in the year 2012. Secondly, we will look at a table of the `holiday` and `cnt`.

```{r}
knitr::kable(aggregate(bikeDataTrain$cnt, by = list(bikeDataTrain$holiday), FUN = sum), col.names = c("Holiday", "Sum of Count"))
```

As expected, this bike sharing company does more business on non-holidays. This makes logical sense as there are more of these days in a year than holidays. Next, we will look at the table of `workingdays` and `cnt`. 

```{r}
knitr::kable(aggregate(bikeDataTrain$cnt, by = list(bikeDataTrain$workingday), FUN = sum), col.names = c("Working Day", "Sum of Count"))
```

From the table, we can see that the count is higher for the weekdays, rather than the weekends, this suggests that bike sharing may be becoming a popular option for the work commute. The next table we will create is of `season` and `cnt`. 

```{r}
knitr::kable(aggregate(bikeDataTrain$cnt, by = list(bikeDataTrain$season), FUN = sum), col.names = c("Season", "Sum of Count"))
```

The most popular seasons appear to be summer and fall. And the least popular season to utilize the bike share is winter. Next, we will look at a table of `mnth` and `cnt`. 

```{r}
knitr::kable(aggregate(bikeDataTrain$cnt, by = list(bikeDataTrain$mnth), FUN = sum), col.names = c("Month", "Sum of Count"))
```

We can see that the most popular months are those that fall in the summer and fall seasons. The last contingency table we will create is for `weather` and `cnt`. 

```{r}
knitr::kable(aggregate(bikeDataTrain$cnt, by = list(bikeDataTrain$weathersit), FUN = sum), col.names = c("Weather", "Sum of Count"))
```

The bike share receives the most use when the weather is nice, with no rain, snow, or thunderstorms. Now, we will create some histograms of the remaining predictors and our reponse variable, `cnt`. We will create these histograms using `ggplot` and `geom_jitter`. The first histogram will contain our `temp` and `cnt` variables. 
```{r}
g <- ggplot(bikeDataTrain, aes(x = temp, y = cnt))
g + geom_jitter() + labs(x = "Normalized Temperature", y = "Count of Total Rental Bikes", title = "Temperature vs. Count")
```

There is a clear positive trend in the histogram, as the temperature becomes warmer, the number of rentals that day increases. The next histogram we look at will contain the `atemp` and `cnt` variables.

```{r}
g <- ggplot(bikeDataTrain, aes(x = atemp, y = cnt))
g + geom_jitter() + labs(x = "Normalized Feeling Temperature", y = "Count of Total Rental Bikes", title = "Feeling Temperature vs. Count")
```

Much like the regular temperature, the temperature that it actually feels like has a positive relationship with the number of rentals. Next, we will create a histogram for the `hum` and `cnt` variables.  

```{r}
g <- ggplot(bikeDataTrain, aes(x = hum, y = cnt))
g + geom_jitter() + labs(x = "Normalized Humidity", y = "Count of Total Rental Bikes", title = "Humidity vs. Count")
```

There doesn't appear to be a definite relationship between the humidity and the count of rental bikes. The final histogram will contain `windspeed` and `cnt`.  

```{r}
g <- ggplot(bikeDataTrain, aes(x = windspeed, y = cnt))
g + geom_jitter() + labs(x = "Normalized Wind Speed", y = "Count of Total Rental Bikes", title = "Wind Speed vs. Count")
```

There appears to be a slight negative relationship between wind speed and the number of rentals that day. Next, we will move on to fitting our models. 

# Models

Now that we have read in our data, created our split, and done some exploratory data analysis, we will begin fitting our models. The goal is to create two models that predict the `cnt` variable in our data set. 

## Non-ensemble Tree Model

The first model we will fit is a regression tree. The main idea of this model is to split up our predictor space into regions, and for a given region, use the main of the observations as our predictor value. For the fitting process of this model, we will use leave one out cross validation. For LOOCV, one observation is removed and the model is fit on the remaining data, and this fit is used to predict the value of the deleted observation. We repeated this process for each observation and compute the mean square error. The data was also centered and scaled using the `preProcess` function. The final choosen model will be the one that minimzes the training RMSE. For the tuning parameter of cp, we will use the default values rather than providing a grid of tuning parameters. 

```{r, warning=FALSE}
(treeFit <- train(cnt ~ ., data = bikeDataTrain,
               method = "rpart",
               preProcess = c("center", "scale"),
               trControl = trainControl(method = "LOOCV")))
```

The optimal model in this case used cp = `r treeFit$bestTune`. And we can see the training RMSE obtained in the output above. 

## Boosted Tree Model 

The final model we will fit is a boosted tree. This model builds off of the previous in that we are sequentially fitting tree models. Each subsequent tree is grown on a modified version of the training data, and we update our predictions as the tree grows. For the fitting process of this model, we will use leave one out cross validation. For LOOCV, one observation is removed and the model is fit on the remaining data, and this fit is used to predict the value of the deleted observation. We repeated this process for each observation and compute the mean square error. The data was also centered and scaled using the `preProcess` function. The final choosen model will be the one that minimzes the training RMSE. For the tuning parameters of number of trees, depth, shrinkage, and minimum number of observations in a node, we will use the default values rather than providing a grid of tuning parameters.

```{r, warning=FALSE}
(boostedtreeFit <- train(cnt ~ ., data = bikeDataTrain,
               method = "gbm",
               preProcess = c("center", "scale"),
               trControl = trainControl(method = "LOOCV"),
               verbose = FALSE))
```

The optimal model in this case used n.trees = `r boostedtreeFit$bestTune[, 1]`, interaction.depth = `r boostedtreeFit$bestTune[, 2]`, shrinkage = `r boostedtreeFit$bestTune[, 3]`, and n.minosbinnode = `r boostedtreeFit$bestTune[, 4]`. And we can see the training RMSE obtained in the output above. 

# Testing Models

Now that we have determined the optimal fit of each model, we will apply our models to the test set. First, we will obtain the test RMSE of the tree model using `predict` and `postResample`. 

```{r}
treePred <- predict(treeFit, newdata = bikeDataTest)
(treeResults <- postResample(treePred, bikeDataTest$cnt))
```

Again, we will use `predict` and `postResample` to obtain the test RMSE of the boosted tree model. 

```{r}
boostedtreePred <- predict(boostedtreeFit, newdata = bikeDataTest)
(boostedtreeResults <- postResample(boostedtreePred, bikeDataTest$cnt))
```

The optimal model in this case is `r ifelse(treeResults[1] < boostedtreeResults[1], "the non-ensemble tree", "the boosted tree")`. And the test RMSE was minimized at `r ifelse(treeResults[1] < boostedtreeResults[1], treeResults[1], boostedtreeResults[1])`. 


# Linear Regression Model
For the last model, a multiple linear regression model shall be added along with the predictions for the model on the test set.

```{r}
lm_model <- lm(cnt ~ ., data = bikeDataTest)
lm_model
```

Now we will predict the values for the multiple linear regression model along with the confidence intervals


```{r}
lm_model_predict <- predict(lm_model, interval = "confidence")
lm_model_predict
```